---
layout: CustomPost
tags: Project
image: /images/project/sign.jpg
lastModified: 2024-04-09
---
# LearnASL (SSC 2024)

For the Swift Student Challenge 2024, I developed an application for teaching the ASL alphabet by interpreting users’ hand poses. it utilizes Vision, CoreML, AVFoundation, and CoreImage to create a system that reads and classifies users’ hand poses from their device camera. I also designed a CreateML Hand Pose Classification model for detecting ASL alphabet signs.

![Swift Student Challenge 2024 Winner](/images/project/SSC2024_Social_Static_16x9.jpg)
